{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math, re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset\n",
    "PATH_X_TRAIN='./wili-2018/x_train.txt'\n",
    "PATH_Y_TRAIN='./wili-2018/y_train.txt'\n",
    "PATH_X_TEST='./wili-2018/x_test.txt'\n",
    "PATH_Y_TEST='./wili-2018/y_test.txt'\n",
    "\n",
    "#parameters\n",
    "COUNT_NGRAMS=20\n",
    "COUNT_SYMBOLS=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read dataset\n",
    "def read_txt(path):\n",
    "    handle = open(path, \"r\", encoding='utf-8')\n",
    "    df = pd.DataFrame(handle.readlines())\n",
    "    handle.close()\n",
    "    return df\n",
    "\n",
    "x_train=read_txt(PATH_X_TRAIN)\n",
    "y_train=read_txt(PATH_Y_TRAIN)\n",
    "x_test=read_txt(PATH_X_TEST)\n",
    "y_test=read_txt(PATH_Y_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean text\n",
    "def clean_text(text):\n",
    "    new_text=''\n",
    "    pos1=text.find('(')\n",
    "    pos2=text.find(')')\n",
    "    if pos2>pos1:\n",
    "        text=text.replace(text[pos1:pos2+1],'')\n",
    "    for t in text:\n",
    "        if t.isalpha():\n",
    "            new_text+=t\n",
    "        elif t.isspace():\n",
    "            new_text+=' '\n",
    "    new_text=re.sub(\" +\",\" \", new_text)\n",
    "    return new_text.replace('\\n','').lower().strip()\n",
    "\n",
    "texts_train=[clean_text(s[0]) for s in x_train.values]\n",
    "texts_test=[clean_text(s[0]) for s in x_test.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classes preprocessing\n",
    "classes_train=y_train.values\n",
    "classes_test=y_test.values\n",
    "\n",
    "classes = np.unique(np.array(classes_train))\n",
    "nums=np.arange(len(classes))\n",
    "d = dict(zip(classes,nums))\n",
    "\n",
    "classes_train=[d[c[0]] for c in classes_train] \n",
    "classes_test=[d[c[0]] for c in classes_test] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make trigrams for classes\n",
    "def make_ngrams(text):\n",
    "    ngrams=[]\n",
    "    if len(text)>COUNT_SYMBOLS+1:\n",
    "        for i in range(len(text)-COUNT_SYMBOLS+1):\n",
    "            ngrams.append(text[i:i+COUNT_SYMBOLS])\n",
    "    return ngrams\n",
    "\n",
    "def add_ngrams(ngrams, l):\n",
    "    for l1 in l:\n",
    "        ngrams.add(l1[0])\n",
    "    return ngrams\n",
    "\n",
    "def collect_ngrams(texts, classes):#collect ngrams for all languages\n",
    "    total_ngrams=set()\n",
    "    for n in nums:\n",
    "        ng_class=set()\n",
    "        i=0\n",
    "        for i in range(len(texts)):\n",
    "            if classes[i]==n:\n",
    "                ng_class.update(make_ngrams(texts[i]))\n",
    "        ng_class=list(ng_class)\n",
    "        ng_count=np.zeros(len(ng_class))\n",
    "        for i in range(len(texts)):\n",
    "            if classes[i]==n:\n",
    "                ngrams=make_ngrams(texts[i])\n",
    "                for ng in ngrams:\n",
    "                    ng_count[ng_class.index(ng)]+=1\n",
    "        ng_class = dict(zip(ng_class,ng_count))\n",
    "        ng_class = sorted(ng_class.items(), key= lambda kv: kv[1], reverse=True)[:COUNT_NGRAMS] \n",
    "        total_ngrams = add_ngrams(total_ngrams, ng_class)\n",
    "    return total_ngrams\n",
    "\n",
    "def ng_freq(text):\n",
    "    text=make_ngrams(text)\n",
    "    freq=np.zeros(len(list_of_ngrams))\n",
    "    for t in text:\n",
    "        if t in list_of_ngrams:\n",
    "            freq[list_of_ngrams.index(t)]+=1\n",
    "    return freq\n",
    "\n",
    "def ngrams_freq(texts, name):\n",
    "    freq=[]\n",
    "    for i, text in enumerate(texts):\n",
    "        freq.append(ng_freq(text))\n",
    "        if i%5000==0 or i==len(texts)-1:\n",
    "            df=pd.DataFrame(freq)\n",
    "            if i==0:\n",
    "                df.to_csv(f, sep=';', index=False) \n",
    "            else:\n",
    "                with open(name, 'a') as f:\n",
    "                    df.to_csv(f, sep=';', index=False, header=False)\n",
    "            freq.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set_of_ngrams = collect_ngrams(texts_train, classes_train)#prepare ngrams\n",
    "\n",
    "with open('set_of_ngrams.dat', 'rb') as f:#load prepared ngrams\n",
    "    set_of_ngrams=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('set_of_ngrams.dat', 'wb') as f:#save ngrams\n",
    "    #pickle.dump(set_of_ngrams, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_ngrams=list(set_of_ngrams)\n",
    "ngrams_freq(texts_train, 'ng_freq_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_freq(texts_test, 'ng_freq_test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
